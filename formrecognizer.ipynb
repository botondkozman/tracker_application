{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/botondkozman/tracker_application/blob/colab/formrecognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaaQaCzUGwd9"
      },
      "source": [
        "# Input parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W13NzM7XBlg2",
        "outputId": "ff6aee92-20b0-4055-dd40-1db0e6f9a634",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import firebase\n"
      ],
      "metadata": {
        "id": "mBViX3D2OncK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import firestore\n",
        "\n",
        "db = None\n",
        "\n",
        "def initialize_firebase():\n",
        "  if not firebase_admin._apps:\n",
        "    cred = credentials.Certificate('/content/drive/MyDrive/credential/odin-demo-2c3f0-firebase-adminsdk-dbjmc-732853d4fe.json')\n",
        "    firebase_admin.initialize_app(cred)\n",
        "\n",
        "def initialize_firestore():\n",
        "  db = firestore.client()\n",
        "  return db\n",
        "\n",
        "def get_collection_data(collection_name):\n",
        "    collection_ref = db.collection(collection_name)\n",
        "    docs = collection_ref.stream()\n",
        "    data = {}\n",
        "    for doc in docs:\n",
        "        data[doc.id] = doc.to_dict()\n",
        "    return data\n",
        "\n",
        "def add_data(collection, document, field):\n",
        "    doc_ref = db.collection(collection).document(document)\n",
        "    doc_ref.set(field)\n",
        "\n",
        "def update_data(collection, document, field):\n",
        "    doc_ref = db.collection(collection).document(document)\n",
        "    doc_ref.update(field)"
      ],
      "metadata": {
        "id": "q516m2yQOmny"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi9u7NfjApWC"
      },
      "source": [
        "# Clone YOLOv5 and download requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy3TBMkt8DwO",
        "outputId": "6af38513-4ed3-4510-ae23-06985254f37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/yolov5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ 2024-10-24 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [00:00<00:00, 219MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import torch\n",
        "\n",
        "folder_path = 'yolov5'\n",
        "%cd /content\n",
        "\n",
        "if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "    print(f\"The folder '{folder_path}' exists.\")\n",
        "else:\n",
        "  subprocess.run(['git', 'clone', 'https://github.com/ultralytics/yolov5.git'])\n",
        "  %cd yolov5\n",
        "  subprocess.run(['pip', 'install', '-r', 'requirements.txt'])\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plpmLUnQW_Hf"
      },
      "source": [
        "# Deleting files from folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uR9BFWOMW-j3"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "def delete_files_and_folders(folder_path):\n",
        "  if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "    files = os.listdir(folder_path)\n",
        "    for file in files:\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
        "  else:\n",
        "    print(f\"The folder '{folder_path}' does not exist or is not a directory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fz80-EACMcR"
      },
      "source": [
        "# Loading the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3irUvg9xCL-n"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def load_image():\n",
        "  folder_path = './data/images/'\n",
        "  delete_files_and_folders(folder_path)\n",
        "\n",
        "  image = cv2.imread(image_url)\n",
        "  size = (image_size[0], image_size[1])\n",
        "  image = cv2.resize(image, size)\n",
        "  cv2.imwrite(folder_path + image_name_with_extension, image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K25QjuxqDk-J"
      },
      "source": [
        "# Running YOLOv5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "39ijVfsnDkud"
      },
      "outputs": [],
      "source": [
        "def run_yolov5():\n",
        "  delete_files_and_folders(output_path)\n",
        "  !python detect.py --source {source} --weights yolov5s.pt --conf 0.05 --save-txt --save-conf --project {output_path} --name {output_name}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMAZR-4AEh1a"
      },
      "source": [
        "\n",
        "# Display detected image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p9uTW0wdEhis"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "def display_image():\n",
        "  path = output_path + '/' + output_name + '/' + image_name\n",
        "  result_img = cv2.imread(path)\n",
        "  plt.imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8LOhzD9On4H"
      },
      "source": [
        "# Extraction of labels into JSON array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CWG7VcjeGtNC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def extract_labels():\n",
        "  first_values = []\n",
        "  json_array = []\n",
        "\n",
        "  labels = model.names\n",
        "  with open(output_path + '/' + output_name + '/labels/' + output_name + '.txt', 'r') as file:\n",
        "      lines = file.readlines()\n",
        "\n",
        "      for line in lines:\n",
        "          line = line.strip()\n",
        "          if line:\n",
        "              first_values.append(line.split()[0])\n",
        "              json_array.append({'label': labels[int(line.split()[0])],\n",
        "                                'rectangle': [float(line.split()[1]), float(line.split()[2]), float(line.split()[3]), float(line.split()[4])]})\n",
        "\n",
        "  return json_array"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dominant color recognition"
      ],
      "metadata": {
        "id": "J_3SsTt0uJQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "\n",
        "color_palette = {\n",
        "    'red': [255, 0, 0],\n",
        "    'green': [0, 255, 0],\n",
        "    'blue': [0, 0, 255],\n",
        "    'yellow': [255, 255, 0],\n",
        "    'cyan': [0, 255, 255],\n",
        "    'magenta': [255, 0, 255],\n",
        "    'black': [0, 0, 0],\n",
        "    'white': [255, 255, 255],\n",
        "    'gray': [128, 128, 128],\n",
        "    'purple': [128, 0, 128],\n",
        "    'orange': [255, 165, 0],\n",
        "    'pink': [255, 192, 203],\n",
        "    'brown': [165, 42, 42],\n",
        "    'lime': [0, 255, 0],\n",
        "    'navy': [0, 0, 128],\n",
        "    'olive': [128, 128, 0],\n",
        "    'teal': [0, 128, 128],\n",
        "    'maroon': [128, 0, 0],\n",
        "    'silver': [192, 192, 192],\n",
        "    'gold': [255, 215, 0]\n",
        "}\n",
        "\n",
        "palette_rgb = np.array(list(color_palette.values()), dtype=np.uint8)\n",
        "\n",
        "def quantize_image(image, palette):\n",
        "    pixels = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=len(palette), random_state=0).fit(pixels)\n",
        "    labels = kmeans.predict(pixels)\n",
        "    quantized_image = palette[labels].reshape(image.shape)\n",
        "    return quantized_image, labels\n",
        "\n",
        "def get_dominant_color(labels, color_names):\n",
        "    label_counts = Counter(labels)\n",
        "    dominant_label = label_counts.most_common(1)[0][0]\n",
        "    dominant_color_name = color_names[dominant_label]\n",
        "    return dominant_color_name, dominant_label\n",
        "\n",
        "def get_dominant_color_rgb():\n",
        "  image = cv2.imread(image_url)\n",
        "  size=(250, 250)\n",
        "  quantized_image, labels = quantize_image(image, palette_rgb)\n",
        "  quantized_image=cv2.resize(quantized_image, size)\n",
        "  height, width, channels = quantized_image.shape\n",
        "  color_names = list(color_palette.keys())\n",
        "  dominant_color, dominant_label = get_dominant_color(labels, color_names)\n",
        "  return dominant_color"
      ],
      "metadata": {
        "id": "gEMBxuG9uI2H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_name = None\n",
        "image_url = None\n",
        "image_name_with_extension = None\n",
        "output_path = 'runs/detect/exp'\n",
        "output_name = image_name\n",
        "source = None\n",
        "image_size = None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  initialize_firebase()\n",
        "  db = initialize_firestore()\n",
        "  docs = get_collection_data('picture')\n",
        "  for doc in docs:\n",
        "    print(doc)\n",
        "    image_name = doc\n",
        "    image_url = '/content/drive/MyDrive/' + (str)(docs.get(doc).get(\"path\"))\n",
        "    image_name_with_extension = image_name + '.' + docs.get(doc).get(\"path\").split(\".\")[1]\n",
        "    output_name = image_name\n",
        "    source = 'data/images/' + image_name_with_extension\n",
        "    image_size = docs.get(doc).get(\"size\")\n",
        "\n",
        "    load_image()\n",
        "    run_yolov5()\n",
        "    json_array = extract_labels()\n",
        "    dominant_color = get_dominant_color_rgb()\n",
        "\n",
        "    update_data('picture', image_name, {'objects': json_array,\n",
        "              'dominant_color': dominant_color})"
      ],
      "metadata": {
        "id": "o3QkmsHPcf42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143a1644-878a-43ec-acc9-c0d08073b069"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_4\n",
            "output_path: runs/detect/exp\n",
            "output_name: image_4\n",
            "source: data/images/image_4.png\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images/image_4.png, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.05, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect/exp, name=image_4, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-378-g2f74455a Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "WARNING âš ï¸ NMS time limit 0.550s exceeded\n",
            "image 1/1 /content/yolov5/data/images/image_4.png: 352x640 1 person, 1 kite, 1 surfboard, 29.1ms\n",
            "Speed: 0.4ms pre-process, 29.1ms inference, 699.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp/image_4\u001b[0m\n",
            "1 labels saved to runs/detect/exp/image_4/labels\n",
            "image_5\n",
            "output_path: runs/detect/exp\n",
            "output_name: image_5\n",
            "source: data/images/image_5.png\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images/image_5.png, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.05, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect/exp, name=image_5, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-378-g2f74455a Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "image 1/1 /content/yolov5/data/images/image_5.png: 352x640 1 cat, 1 bowl, 1 orange, 2 carrots, 1 dining table, 28.7ms\n",
            "Speed: 0.4ms pre-process, 28.7ms inference, 526.6ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp/image_5\u001b[0m\n",
            "1 labels saved to runs/detect/exp/image_5/labels\n",
            "image_6\n",
            "output_path: runs/detect/exp\n",
            "output_name: image_6\n",
            "source: data/images/image_6.png\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images/image_6.png, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.05, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect/exp, name=image_6, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-378-g2f74455a Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "WARNING âš ï¸ NMS time limit 0.550s exceeded\n",
            "image 1/1 /content/yolov5/data/images/image_6.png: 352x640 1 person, 1 handbag, 1 clock, 29.2ms\n",
            "Speed: 0.5ms pre-process, 29.2ms inference, 620.2ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp/image_6\u001b[0m\n",
            "1 labels saved to runs/detect/exp/image_6/labels\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}